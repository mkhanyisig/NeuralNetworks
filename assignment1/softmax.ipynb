{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax exercise\n",
    "\n",
    "*Complete and hand in this completed worksheet (including its outputs and any supporting code outside of the worksheet) with your assignment submission. For more details see the [assignments page](http://vision.stanford.edu/teaching/cs231n/assignments.html) on the course website.*\n",
    "\n",
    "This exercise is analogous to the SVM exercise. You will:\n",
    "\n",
    "- implement a fully-vectorized **loss function** for the Softmax classifier\n",
    "- implement the fully-vectorized expression for its **analytic gradient**\n",
    "- **check your implementation** with numerical gradient\n",
    "- use a validation set to **tune the learning rate and regularization** strength\n",
    "- **optimize** the loss function with **SGD**\n",
    "\n",
    "- **visualize** the final learned weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "setup done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import random\n",
    "import numpy as np\n",
    "from cs231n.data_utils import load_CIFAR10\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading extenrnal modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "print (\"setup done\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clear previously loaded data.\n",
      "Train data shape:  (49000, 3073)\n",
      "Train labels shape:  (49000,)\n",
      "Validation data shape:  (1000, 3073)\n",
      "Validation labels shape:  (1000,)\n",
      "Test data shape:  (1000, 3073)\n",
      "Test labels shape:  (1000,)\n",
      "dev data shape:  (500, 3073)\n",
      "dev labels shape:  (500,)\n"
     ]
    }
   ],
   "source": [
    "def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=1000, num_dev=500):\n",
    "    \"\"\"\n",
    "    Load the CIFAR-10 dataset from disk and perform preprocessing to prepare\n",
    "    it for the linear classifier. These are the same steps as we used for the\n",
    "    SVM, but condensed to a single function.  \n",
    "    \"\"\"\n",
    "    # Load the raw CIFAR-10 data\n",
    "    cifar10_dir = 'cs231n/datasets/cifar-10-batches-py'\n",
    "    \n",
    "    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "    \n",
    "    # subsample the data\n",
    "    mask = list(range(num_training, num_training + num_validation))\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = list(range(num_training))\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = list(range(num_test))\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "    mask = np.random.choice(num_training, num_dev, replace=False)\n",
    "    X_dev = X_train[mask]\n",
    "    y_dev = y_train[mask]\n",
    "    \n",
    "    # Preprocessing: reshape the image data into rows\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
    "    X_val = np.reshape(X_val, (X_val.shape[0], -1))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
    "    X_dev = np.reshape(X_dev, (X_dev.shape[0], -1))\n",
    "    \n",
    "    # Normalize the data: subtract the mean image\n",
    "    mean_image = np.mean(X_train, axis = 0)\n",
    "    X_train -= mean_image\n",
    "    X_val -= mean_image\n",
    "    X_test -= mean_image\n",
    "    X_dev -= mean_image\n",
    "    \n",
    "    # add bias dimension and transform into columns\n",
    "    X_train = np.hstack([X_train, np.ones((X_train.shape[0], 1))])\n",
    "    X_val = np.hstack([X_val, np.ones((X_val.shape[0], 1))])\n",
    "    X_test = np.hstack([X_test, np.ones((X_test.shape[0], 1))])\n",
    "    X_dev = np.hstack([X_dev, np.ones((X_dev.shape[0], 1))])\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev\n",
    "\n",
    "\n",
    "# Cleaning up variables to prevent loading data multiple times (which may cause memory issue)\n",
    "try:\n",
    "   del X_train, y_train\n",
    "   del X_test, y_test\n",
    "   print('Clear previously loaded data.')\n",
    "except:\n",
    "   pass\n",
    "\n",
    "# Invoke the above function to get our data.\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev = get_CIFAR10_data()\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)\n",
    "print('dev data shape: ', X_dev.shape)\n",
    "print('dev labels shape: ', y_dev.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Classifier\n",
    "\n",
    "Your code for this section will all be written inside **cs231n/classifiers/softmax.py**. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.334109\n",
      "sanity check: 2.302585\n"
     ]
    }
   ],
   "source": [
    "# First implement the naive softmax loss function with nested loops.\n",
    "# Open the file cs231n/classifiers/softmax.py and implement the\n",
    "# softmax_loss_naive function.\n",
    "\n",
    "from cs231n.classifiers.softmax import softmax_loss_naive\n",
    "import time\n",
    "\n",
    "# Generate a random softmax weight matrix and use it to compute the loss.\n",
    "W = np.random.randn(3073, 10) * 0.0001\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)\n",
    "\n",
    "# As a rough sanity check, our loss should be something close to -log(0.1).\n",
    "print('loss: %f' % loss)\n",
    "print('sanity check: %f' % (-np.log(0.1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inline Question 1:\n",
    "Why do we expect our loss to be close to -log(0.1)? Explain briefly.**\n",
    "\n",
    "**Your answer:** * For our data, there are 10 possible classes and only one correct class for the ground truth tables. There is a 0.1 chance of random guess for each class, our loss is giving unnormalised negative log probabilities of each class so should be close to -log(0.1) at the start (random guess). *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical: 2.165246 analytic: 2.165246, relative error: 4.476693e-08\n",
      "numerical: -0.863869 analytic: -0.863870, relative error: 1.692829e-08\n",
      "numerical: -0.243418 analytic: -0.243418, relative error: 1.595240e-07\n",
      "numerical: 3.573190 analytic: 3.573190, relative error: 2.497173e-08\n",
      "numerical: -1.534077 analytic: -1.534077, relative error: 9.325362e-09\n",
      "numerical: -0.585371 analytic: -0.585371, relative error: 5.199210e-08\n",
      "numerical: -2.554850 analytic: -2.554850, relative error: 5.046925e-09\n",
      "numerical: 0.770071 analytic: 0.770071, relative error: 6.735276e-08\n",
      "numerical: 0.996441 analytic: 0.996440, relative error: 1.859009e-08\n",
      "numerical: 3.407291 analytic: 3.407291, relative error: 8.668087e-09\n",
      "numerical: 2.490740 analytic: 2.490739, relative error: 3.269095e-08\n",
      "numerical: 0.018444 analytic: 0.018444, relative error: 1.160115e-06\n",
      "numerical: 0.086835 analytic: 0.086835, relative error: 6.972341e-07\n",
      "numerical: -0.788320 analytic: -0.788320, relative error: 5.693500e-09\n",
      "numerical: 0.637140 analytic: 0.637140, relative error: 4.338068e-08\n",
      "numerical: 0.027111 analytic: 0.027111, relative error: 7.831247e-07\n",
      "numerical: 0.908870 analytic: 0.908870, relative error: 6.808412e-08\n",
      "numerical: 0.228242 analytic: 0.228242, relative error: 4.526002e-08\n",
      "numerical: 1.509984 analytic: 1.509984, relative error: 3.600044e-08\n",
      "numerical: -1.879903 analytic: -1.879903, relative error: 4.262893e-08\n",
      "done checking :) \n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Complete the implementation of softmax_loss_naive and implement a (naive)\n",
    "# version of the gradient that uses nested loops.\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)\n",
    "\n",
    "# As we did for the SVM, use numeric gradient checking as a debugging tool.\n",
    "# The numeric gradient should be close to the analytic gradient.\n",
    "from cs231n.gradient_check import grad_check_sparse\n",
    "f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 0.0)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, grad, 10)\n",
    "\n",
    "# similar to SVM case, do another gradient check with regularization\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 5e1)\n",
    "f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 5e1)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, grad, 10)\n",
    "print (\"done checking :) \\n \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive loss: 2.334109e+00 computed in 0.231904s\n",
      "vectorized loss: 2.334109e+00 computed in 0.015656s\n",
      "Loss difference: 0.000000\n",
      "Gradient difference: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Now that we have a naive implementation of the softmax loss function and its gradient,\n",
    "# implement a vectorized version in softmax_loss_vectorized.\n",
    "# The two versions should compute the same results, but the vectorized version should be\n",
    "# much faster.\n",
    "tic = time.time()\n",
    "loss_naive, grad_naive = softmax_loss_naive(W, X_dev, y_dev, 0.000005)\n",
    "toc = time.time()\n",
    "print('naive loss: %e computed in %fs' % (loss_naive, toc - tic))\n",
    "\n",
    "from cs231n.classifiers.softmax import softmax_loss_vectorized\n",
    "tic = time.time()\n",
    "loss_vectorized, grad_vectorized = softmax_loss_vectorized(W, X_dev, y_dev, 0.000005)\n",
    "toc = time.time()\n",
    "print('vectorized loss: %e computed in %fs' % (loss_vectorized, toc - tic))\n",
    "\n",
    "# As we did for the SVM, we use the Frobenius norm to compare the two versions\n",
    "# of the gradient.\n",
    "grad_difference = np.linalg.norm(grad_naive - grad_vectorized, ord='fro')\n",
    "print('Loss difference: %f' % np.abs(loss_naive - loss_vectorized))\n",
    "print('Gradient difference: %f' % grad_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strating loop ! This may take a while\n",
      "\n",
      "\n",
      "iteration 0 / 1600: loss 395.338651\n",
      "iteration 100 / 1600: loss 239.013424\n",
      "iteration 200 / 1600: loss 145.153142\n",
      "iteration 300 / 1600: loss 88.584269\n",
      "iteration 400 / 1600: loss 54.297126\n",
      "iteration 500 / 1600: loss 33.750134\n",
      "iteration 600 / 1600: loss 21.178037\n",
      "iteration 700 / 1600: loss 13.619623\n",
      "iteration 800 / 1600: loss 9.068348\n",
      "iteration 900 / 1600: loss 6.222027\n",
      "iteration 1000 / 1600: loss 4.629920\n",
      "iteration 1100 / 1600: loss 3.584675\n",
      "iteration 1200 / 1600: loss 2.901236\n",
      "iteration 1300 / 1600: loss 2.573211\n",
      "iteration 1400 / 1600: loss 2.359519\n",
      "iteration 1500 / 1600: loss 2.220186\n",
      "iteration 0 / 1600: loss 483.373433\n",
      "iteration 100 / 1600: loss 258.306914\n",
      "iteration 200 / 1600: loss 138.624373\n",
      "iteration 300 / 1600: loss 74.983773\n",
      "iteration 400 / 1600: loss 40.859433\n",
      "iteration 500 / 1600: loss 22.810248\n",
      "iteration 600 / 1600: loss 13.058675\n",
      "iteration 700 / 1600: loss 7.871121\n",
      "iteration 800 / 1600: loss 5.160931\n",
      "iteration 900 / 1600: loss 3.731637\n",
      "iteration 1000 / 1600: loss 2.904479\n",
      "iteration 1100 / 1600: loss 2.528300\n",
      "iteration 1200 / 1600: loss 2.357585\n",
      "iteration 1300 / 1600: loss 2.151734\n",
      "iteration 1400 / 1600: loss 2.088765\n",
      "iteration 1500 / 1600: loss 2.137322\n",
      "iteration 0 / 1600: loss 579.780248\n",
      "iteration 100 / 1600: loss 273.887898\n",
      "iteration 200 / 1600: loss 129.679805\n",
      "iteration 300 / 1600: loss 62.085737\n",
      "iteration 400 / 1600: loss 30.328453\n",
      "iteration 500 / 1600: loss 15.368541\n",
      "iteration 600 / 1600: loss 8.306926\n",
      "iteration 700 / 1600: loss 5.036042\n",
      "iteration 800 / 1600: loss 3.443271\n",
      "iteration 900 / 1600: loss 2.765635\n",
      "iteration 1000 / 1600: loss 2.381657\n",
      "iteration 1100 / 1600: loss 2.221403\n",
      "iteration 1200 / 1600: loss 2.158739\n",
      "iteration 1300 / 1600: loss 2.107679\n",
      "iteration 1400 / 1600: loss 2.090771\n",
      "iteration 1500 / 1600: loss 2.005758\n",
      "iteration 0 / 1600: loss 676.237765\n",
      "iteration 100 / 1600: loss 281.259409\n",
      "iteration 200 / 1600: loss 118.043836\n",
      "iteration 300 / 1600: loss 50.237832\n",
      "iteration 400 / 1600: loss 21.981392\n",
      "iteration 500 / 1600: loss 10.333832\n",
      "iteration 600 / 1600: loss 5.522526\n",
      "iteration 700 / 1600: loss 3.505078\n",
      "iteration 800 / 1600: loss 2.708618\n",
      "iteration 900 / 1600: loss 2.326545\n",
      "iteration 1000 / 1600: loss 2.183757\n",
      "iteration 1100 / 1600: loss 2.118260\n",
      "iteration 1200 / 1600: loss 2.073882\n",
      "iteration 1300 / 1600: loss 2.154066\n",
      "iteration 1400 / 1600: loss 2.130312\n",
      "iteration 1500 / 1600: loss 2.086252\n",
      "iteration 0 / 1600: loss 779.139996\n",
      "iteration 100 / 1600: loss 285.764254\n",
      "iteration 200 / 1600: loss 105.966744\n",
      "iteration 300 / 1600: loss 40.032313\n",
      "iteration 400 / 1600: loss 15.991679\n",
      "iteration 500 / 1600: loss 7.159524\n",
      "iteration 600 / 1600: loss 3.982132\n",
      "iteration 700 / 1600: loss 2.763481\n",
      "iteration 800 / 1600: loss 2.374113\n",
      "iteration 900 / 1600: loss 2.187468\n",
      "iteration 1000 / 1600: loss 2.035153\n",
      "iteration 1100 / 1600: loss 2.076702\n",
      "iteration 1200 / 1600: loss 2.093679\n",
      "iteration 1300 / 1600: loss 2.052496\n",
      "iteration 1400 / 1600: loss 2.027612\n",
      "iteration 1500 / 1600: loss 2.073934\n",
      "iteration 0 / 1600: loss 393.947795\n",
      "iteration 100 / 1600: loss 144.404964\n",
      "iteration 200 / 1600: loss 53.867630\n",
      "iteration 300 / 1600: loss 20.969404\n",
      "iteration 400 / 1600: loss 8.943559\n",
      "iteration 500 / 1600: loss 4.610170\n",
      "iteration 600 / 1600: loss 2.999448\n",
      "iteration 700 / 1600: loss 2.413722\n",
      "iteration 800 / 1600: loss 2.198936\n",
      "iteration 900 / 1600: loss 2.045505\n",
      "iteration 1000 / 1600: loss 2.128481\n",
      "iteration 1100 / 1600: loss 2.025738\n",
      "iteration 1200 / 1600: loss 2.001638\n",
      "iteration 1300 / 1600: loss 1.998919\n",
      "iteration 1400 / 1600: loss 2.026524\n",
      "iteration 1500 / 1600: loss 1.985756\n",
      "iteration 0 / 1600: loss 485.872845\n",
      "iteration 100 / 1600: loss 138.615257\n",
      "iteration 200 / 1600: loss 40.922240\n",
      "iteration 300 / 1600: loss 13.111542\n",
      "iteration 400 / 1600: loss 5.197297\n",
      "iteration 500 / 1600: loss 2.962451\n",
      "iteration 600 / 1600: loss 2.318063\n",
      "iteration 700 / 1600: loss 2.106254\n",
      "iteration 800 / 1600: loss 2.024339\n",
      "iteration 900 / 1600: loss 2.021715\n",
      "iteration 1000 / 1600: loss 2.029740\n",
      "iteration 1100 / 1600: loss 2.038453\n",
      "iteration 1200 / 1600: loss 2.004126\n",
      "iteration 1300 / 1600: loss 2.012466\n",
      "iteration 1400 / 1600: loss 2.067397\n",
      "iteration 1500 / 1600: loss 2.009766\n",
      "iteration 0 / 1600: loss 584.910059\n",
      "iteration 100 / 1600: loss 130.436418\n",
      "iteration 200 / 1600: loss 30.386132\n",
      "iteration 300 / 1600: loss 8.309932\n",
      "iteration 400 / 1600: loss 3.510046\n",
      "iteration 500 / 1600: loss 2.363582\n",
      "iteration 600 / 1600: loss 2.059584\n",
      "iteration 700 / 1600: loss 2.058715\n",
      "iteration 800 / 1600: loss 2.120440\n",
      "iteration 900 / 1600: loss 2.004193\n",
      "iteration 1000 / 1600: loss 2.065732\n",
      "iteration 1100 / 1600: loss 2.081511\n",
      "iteration 1200 / 1600: loss 2.126301\n",
      "iteration 1300 / 1600: loss 2.084860\n",
      "iteration 1400 / 1600: loss 2.040726\n",
      "iteration 1500 / 1600: loss 2.037489\n",
      "iteration 0 / 1600: loss 679.223072\n",
      "iteration 100 / 1600: loss 117.773963\n",
      "iteration 200 / 1600: loss 21.949637\n",
      "iteration 300 / 1600: loss 5.554129\n",
      "iteration 400 / 1600: loss 2.731647\n",
      "iteration 500 / 1600: loss 2.194066\n",
      "iteration 600 / 1600: loss 2.101777\n",
      "iteration 700 / 1600: loss 2.060093\n",
      "iteration 800 / 1600: loss 2.116886\n",
      "iteration 900 / 1600: loss 2.131866\n",
      "iteration 1000 / 1600: loss 2.095893\n",
      "iteration 1100 / 1600: loss 1.998760\n",
      "iteration 1200 / 1600: loss 2.070126\n",
      "iteration 1300 / 1600: loss 2.084637\n",
      "iteration 1400 / 1600: loss 2.100373\n",
      "iteration 1500 / 1600: loss 2.082595\n",
      "iteration 0 / 1600: loss 776.143791\n",
      "iteration 100 / 1600: loss 104.971835\n",
      "iteration 200 / 1600: loss 15.826922\n",
      "iteration 300 / 1600: loss 3.949945\n",
      "iteration 400 / 1600: loss 2.331116\n",
      "iteration 500 / 1600: loss 2.104409\n",
      "iteration 600 / 1600: loss 2.101880\n",
      "iteration 700 / 1600: loss 2.074515\n",
      "iteration 800 / 1600: loss 2.070585\n",
      "iteration 900 / 1600: loss 2.063432\n",
      "iteration 1000 / 1600: loss 2.075900\n",
      "iteration 1100 / 1600: loss 2.102091\n",
      "iteration 1200 / 1600: loss 2.070459\n",
      "iteration 1300 / 1600: loss 2.114980\n",
      "iteration 1400 / 1600: loss 2.060056\n",
      "iteration 1500 / 1600: loss 2.061295\n",
      "iteration 0 / 1600: loss 392.213372\n",
      "iteration 100 / 1600: loss 87.401826\n",
      "iteration 200 / 1600: loss 20.878887\n",
      "iteration 300 / 1600: loss 6.253804\n",
      "iteration 400 / 1600: loss 2.950693\n",
      "iteration 500 / 1600: loss 2.250532\n",
      "iteration 600 / 1600: loss 2.074851\n",
      "iteration 700 / 1600: loss 1.955204\n",
      "iteration 800 / 1600: loss 2.078445\n",
      "iteration 900 / 1600: loss 2.026476\n",
      "iteration 1000 / 1600: loss 2.097814\n",
      "iteration 1100 / 1600: loss 2.009314\n",
      "iteration 1200 / 1600: loss 2.042749\n",
      "iteration 1300 / 1600: loss 1.985079\n",
      "iteration 1400 / 1600: loss 2.093901\n",
      "iteration 1500 / 1600: loss 1.980142\n",
      "iteration 0 / 1600: loss 487.035348\n",
      "iteration 100 / 1600: loss 75.012151\n",
      "iteration 200 / 1600: loss 13.051090\n",
      "iteration 300 / 1600: loss 3.755341\n",
      "iteration 400 / 1600: loss 2.274365\n",
      "iteration 500 / 1600: loss 2.119243\n",
      "iteration 600 / 1600: loss 2.035407\n",
      "iteration 700 / 1600: loss 1.976939\n",
      "iteration 800 / 1600: loss 2.002256\n",
      "iteration 900 / 1600: loss 2.047338\n",
      "iteration 1000 / 1600: loss 2.018707\n",
      "iteration 1100 / 1600: loss 1.987311\n",
      "iteration 1200 / 1600: loss 2.029764\n",
      "iteration 1300 / 1600: loss 2.022479\n",
      "iteration 1400 / 1600: loss 2.012726\n",
      "iteration 1500 / 1600: loss 2.088762\n",
      "iteration 0 / 1600: loss 592.191118\n",
      "iteration 100 / 1600: loss 62.837014\n",
      "iteration 200 / 1600: loss 8.357127\n",
      "iteration 300 / 1600: loss 2.651312\n",
      "iteration 400 / 1600: loss 2.133271\n",
      "iteration 500 / 1600: loss 2.060363\n",
      "iteration 600 / 1600: loss 2.019282\n",
      "iteration 700 / 1600: loss 2.063272\n",
      "iteration 800 / 1600: loss 2.059574\n",
      "iteration 900 / 1600: loss 2.080019\n",
      "iteration 1000 / 1600: loss 2.067819\n",
      "iteration 1100 / 1600: loss 2.062447\n",
      "iteration 1200 / 1600: loss 2.127812\n",
      "iteration 1300 / 1600: loss 2.069283\n",
      "iteration 1400 / 1600: loss 2.073945\n",
      "iteration 1500 / 1600: loss 2.097180\n",
      "iteration 0 / 1600: loss 682.894030\n",
      "iteration 100 / 1600: loss 50.113322\n",
      "iteration 200 / 1600: loss 5.479543\n",
      "iteration 300 / 1600: loss 2.319687\n",
      "iteration 400 / 1600: loss 2.109819\n",
      "iteration 500 / 1600: loss 2.115183\n",
      "iteration 600 / 1600: loss 2.094736\n",
      "iteration 700 / 1600: loss 2.031515\n",
      "iteration 800 / 1600: loss 2.090897\n",
      "iteration 900 / 1600: loss 2.068028\n",
      "iteration 1000 / 1600: loss 2.095652\n",
      "iteration 1100 / 1600: loss 2.018039\n",
      "iteration 1200 / 1600: loss 2.108649\n",
      "iteration 1300 / 1600: loss 2.106023\n",
      "iteration 1400 / 1600: loss 2.058843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1500 / 1600: loss 2.131564\n",
      "iteration 0 / 1600: loss 768.836897\n",
      "iteration 100 / 1600: loss 38.977949\n",
      "iteration 200 / 1600: loss 3.831379\n",
      "iteration 300 / 1600: loss 2.208679\n",
      "iteration 400 / 1600: loss 2.084622\n",
      "iteration 500 / 1600: loss 2.043094\n",
      "iteration 600 / 1600: loss 2.067673\n",
      "iteration 700 / 1600: loss 2.102761\n",
      "iteration 800 / 1600: loss 2.071990\n",
      "iteration 900 / 1600: loss 2.015166\n",
      "iteration 1000 / 1600: loss 2.139711\n",
      "iteration 1100 / 1600: loss 2.051476\n",
      "iteration 1200 / 1600: loss 2.087506\n",
      "iteration 1300 / 1600: loss 2.089236\n",
      "iteration 1400 / 1600: loss 2.095975\n",
      "iteration 1500 / 1600: loss 2.090713\n",
      "iteration 0 / 1600: loss 393.560552\n",
      "iteration 100 / 1600: loss 53.639321\n",
      "iteration 200 / 1600: loss 8.917883\n",
      "iteration 300 / 1600: loss 3.008684\n",
      "iteration 400 / 1600: loss 2.085048\n",
      "iteration 500 / 1600: loss 2.025506\n",
      "iteration 600 / 1600: loss 1.989612\n",
      "iteration 700 / 1600: loss 2.002224\n",
      "iteration 800 / 1600: loss 2.049280\n",
      "iteration 900 / 1600: loss 2.091533\n",
      "iteration 1000 / 1600: loss 1.980554\n",
      "iteration 1100 / 1600: loss 2.045975\n",
      "iteration 1200 / 1600: loss 2.059084\n",
      "iteration 1300 / 1600: loss 2.019877\n",
      "iteration 1400 / 1600: loss 1.999089\n",
      "iteration 1500 / 1600: loss 2.026256\n",
      "iteration 0 / 1600: loss 483.153852\n",
      "iteration 100 / 1600: loss 40.453720\n",
      "iteration 200 / 1600: loss 5.069005\n",
      "iteration 300 / 1600: loss 2.314994\n",
      "iteration 400 / 1600: loss 2.037598\n",
      "iteration 500 / 1600: loss 2.021294\n",
      "iteration 600 / 1600: loss 2.079169\n",
      "iteration 700 / 1600: loss 2.008426\n",
      "iteration 800 / 1600: loss 2.034038\n",
      "iteration 900 / 1600: loss 2.022563\n",
      "iteration 1000 / 1600: loss 1.978705\n",
      "iteration 1100 / 1600: loss 1.965484\n",
      "iteration 1200 / 1600: loss 2.090652\n",
      "iteration 1300 / 1600: loss 2.120992\n",
      "iteration 1400 / 1600: loss 2.055286\n",
      "iteration 1500 / 1600: loss 2.112776\n",
      "iteration 0 / 1600: loss 588.580416\n",
      "iteration 100 / 1600: loss 30.181105\n",
      "iteration 200 / 1600: loss 3.405222\n",
      "iteration 300 / 1600: loss 2.071667\n",
      "iteration 400 / 1600: loss 2.038566\n",
      "iteration 500 / 1600: loss 2.056223\n",
      "iteration 600 / 1600: loss 2.098403\n",
      "iteration 700 / 1600: loss 2.092812\n",
      "iteration 800 / 1600: loss 2.019171\n",
      "iteration 900 / 1600: loss 2.046801\n",
      "iteration 1000 / 1600: loss 2.039109\n",
      "iteration 1100 / 1600: loss 2.063910\n",
      "iteration 1200 / 1600: loss 2.048378\n",
      "iteration 1300 / 1600: loss 2.035152\n",
      "iteration 1400 / 1600: loss 2.029736\n",
      "iteration 1500 / 1600: loss 2.006456\n",
      "iteration 0 / 1600: loss 677.318345\n",
      "iteration 100 / 1600: loss 21.607735\n",
      "iteration 200 / 1600: loss 2.632988\n",
      "iteration 300 / 1600: loss 2.097410\n",
      "iteration 400 / 1600: loss 2.091945\n",
      "iteration 500 / 1600: loss 2.078524\n",
      "iteration 600 / 1600: loss 2.033478\n",
      "iteration 700 / 1600: loss 2.055746\n",
      "iteration 800 / 1600: loss 2.059050\n",
      "iteration 900 / 1600: loss 2.108138\n",
      "iteration 1000 / 1600: loss 2.134962\n",
      "iteration 1100 / 1600: loss 2.071335\n",
      "iteration 1200 / 1600: loss 2.060511\n",
      "iteration 1300 / 1600: loss 2.052799\n",
      "iteration 1400 / 1600: loss 2.070894\n",
      "iteration 1500 / 1600: loss 2.076145\n",
      "iteration 0 / 1600: loss 766.998740\n",
      "iteration 100 / 1600: loss 15.371568\n",
      "iteration 200 / 1600: loss 2.335287\n",
      "iteration 300 / 1600: loss 2.105824\n",
      "iteration 400 / 1600: loss 2.053600\n",
      "iteration 500 / 1600: loss 2.121679\n",
      "iteration 600 / 1600: loss 2.080746\n",
      "iteration 700 / 1600: loss 2.033233\n",
      "iteration 800 / 1600: loss 2.161257\n",
      "iteration 900 / 1600: loss 2.108820\n",
      "iteration 1000 / 1600: loss 2.033108\n",
      "iteration 1100 / 1600: loss 2.039316\n",
      "iteration 1200 / 1600: loss 2.047719\n",
      "iteration 1300 / 1600: loss 2.100564\n",
      "iteration 1400 / 1600: loss 2.099164\n",
      "iteration 1500 / 1600: loss 2.057109\n",
      "iteration 0 / 1600: loss 395.135583\n",
      "iteration 100 / 1600: loss 33.289213\n",
      "iteration 200 / 1600: loss 4.608725\n",
      "iteration 300 / 1600: loss 2.133125\n",
      "iteration 400 / 1600: loss 2.060672\n",
      "iteration 500 / 1600: loss 2.021403\n",
      "iteration 600 / 1600: loss 1.965202\n",
      "iteration 700 / 1600: loss 2.086646\n",
      "iteration 800 / 1600: loss 2.081815\n",
      "iteration 900 / 1600: loss 2.081936\n",
      "iteration 1000 / 1600: loss 2.063446\n",
      "iteration 1100 / 1600: loss 2.029845\n",
      "iteration 1200 / 1600: loss 2.106432\n",
      "iteration 1300 / 1600: loss 2.055154\n",
      "iteration 1400 / 1600: loss 1.973042\n",
      "iteration 1500 / 1600: loss 1.988735\n",
      "iteration 0 / 1600: loss 484.342771\n",
      "iteration 100 / 1600: loss 22.396722\n",
      "iteration 200 / 1600: loss 2.866828\n",
      "iteration 300 / 1600: loss 2.067929\n",
      "iteration 400 / 1600: loss 2.005821\n",
      "iteration 500 / 1600: loss 2.020192\n",
      "iteration 600 / 1600: loss 2.070837\n",
      "iteration 700 / 1600: loss 2.014329\n",
      "iteration 800 / 1600: loss 2.031582\n",
      "iteration 900 / 1600: loss 2.096414\n",
      "iteration 1000 / 1600: loss 2.101531\n",
      "iteration 1100 / 1600: loss 2.070827\n",
      "iteration 1200 / 1600: loss 2.070121\n",
      "iteration 1300 / 1600: loss 2.015660\n",
      "iteration 1400 / 1600: loss 2.055274\n",
      "iteration 1500 / 1600: loss 2.051645\n",
      "iteration 0 / 1600: loss 584.876492\n",
      "iteration 100 / 1600: loss 15.104846\n",
      "iteration 200 / 1600: loss 2.323504\n",
      "iteration 300 / 1600: loss 2.065238\n",
      "iteration 400 / 1600: loss 2.062476\n",
      "iteration 500 / 1600: loss 2.131096\n",
      "iteration 600 / 1600: loss 2.019215\n",
      "iteration 700 / 1600: loss 2.085009\n",
      "iteration 800 / 1600: loss 2.093049\n",
      "iteration 900 / 1600: loss 2.051019\n",
      "iteration 1000 / 1600: loss 2.030579\n",
      "iteration 1100 / 1600: loss 2.059834\n",
      "iteration 1200 / 1600: loss 2.070101\n",
      "iteration 1300 / 1600: loss 2.016472\n",
      "iteration 1400 / 1600: loss 2.024651\n",
      "iteration 1500 / 1600: loss 2.099518\n",
      "iteration 0 / 1600: loss 678.129238\n",
      "iteration 100 / 1600: loss 10.071663\n",
      "iteration 200 / 1600: loss 2.191111\n",
      "iteration 300 / 1600: loss 2.112896\n",
      "iteration 400 / 1600: loss 2.127791\n",
      "iteration 500 / 1600: loss 2.071063\n",
      "iteration 600 / 1600: loss 2.090938\n",
      "iteration 700 / 1600: loss 2.081788\n",
      "iteration 800 / 1600: loss 2.079494\n",
      "iteration 900 / 1600: loss 2.123902\n",
      "iteration 1000 / 1600: loss 2.021544\n",
      "iteration 1100 / 1600: loss 2.121497\n",
      "iteration 1200 / 1600: loss 2.117409\n",
      "iteration 1300 / 1600: loss 2.056931\n",
      "iteration 1400 / 1600: loss 2.082827\n",
      "iteration 1500 / 1600: loss 2.098174\n",
      "iteration 0 / 1600: loss 770.064107\n",
      "iteration 100 / 1600: loss 6.899345\n",
      "iteration 200 / 1600: loss 2.117444\n",
      "iteration 300 / 1600: loss 2.114202\n",
      "iteration 400 / 1600: loss 2.104328\n",
      "iteration 500 / 1600: loss 2.112189\n",
      "iteration 600 / 1600: loss 2.158395\n",
      "iteration 700 / 1600: loss 2.109149\n",
      "iteration 800 / 1600: loss 2.101754\n",
      "iteration 900 / 1600: loss 2.107814\n",
      "iteration 1000 / 1600: loss 2.155126\n",
      "iteration 1100 / 1600: loss 2.082351\n",
      "iteration 1200 / 1600: loss 2.097180\n",
      "iteration 1300 / 1600: loss 2.063837\n",
      "iteration 1400 / 1600: loss 2.130410\n",
      "iteration 1500 / 1600: loss 2.072195\n",
      "\n",
      "****\n",
      "done comparing\n",
      "****\n",
      "\n",
      "best_val     0.369\n",
      "\n",
      "best_lr      2e-07\n",
      "\n",
      "best_reg     37500.0\n",
      "\n",
      "best Softmax model saved :)\n",
      "\n",
      "lr 1.000000e-07 reg 2.500000e+04 train accuracy: 0.352306 val accuracy: 0.366000\n",
      "lr 1.000000e-07 reg 3.125000e+04 train accuracy: 0.343857 val accuracy: 0.355000\n",
      "lr 1.000000e-07 reg 3.750000e+04 train accuracy: 0.338367 val accuracy: 0.357000\n",
      "lr 1.000000e-07 reg 4.375000e+04 train accuracy: 0.334571 val accuracy: 0.341000\n",
      "lr 1.000000e-07 reg 5.000000e+04 train accuracy: 0.332224 val accuracy: 0.349000\n",
      "lr 2.000000e-07 reg 2.500000e+04 train accuracy: 0.353408 val accuracy: 0.366000\n",
      "lr 2.000000e-07 reg 3.125000e+04 train accuracy: 0.342327 val accuracy: 0.360000\n",
      "lr 2.000000e-07 reg 3.750000e+04 train accuracy: 0.342551 val accuracy: 0.369000\n",
      "lr 2.000000e-07 reg 4.375000e+04 train accuracy: 0.330980 val accuracy: 0.342000\n",
      "lr 2.000000e-07 reg 5.000000e+04 train accuracy: 0.330571 val accuracy: 0.343000\n",
      "lr 3.000000e-07 reg 2.500000e+04 train accuracy: 0.351469 val accuracy: 0.369000\n",
      "lr 3.000000e-07 reg 3.125000e+04 train accuracy: 0.341388 val accuracy: 0.361000\n",
      "lr 3.000000e-07 reg 3.750000e+04 train accuracy: 0.341694 val accuracy: 0.348000\n",
      "lr 3.000000e-07 reg 4.375000e+04 train accuracy: 0.336020 val accuracy: 0.341000\n",
      "lr 3.000000e-07 reg 5.000000e+04 train accuracy: 0.329735 val accuracy: 0.347000\n",
      "lr 4.000000e-07 reg 2.500000e+04 train accuracy: 0.349306 val accuracy: 0.366000\n",
      "lr 4.000000e-07 reg 3.125000e+04 train accuracy: 0.334796 val accuracy: 0.347000\n",
      "lr 4.000000e-07 reg 3.750000e+04 train accuracy: 0.337837 val accuracy: 0.345000\n",
      "lr 4.000000e-07 reg 4.375000e+04 train accuracy: 0.332041 val accuracy: 0.344000\n",
      "lr 4.000000e-07 reg 5.000000e+04 train accuracy: 0.324918 val accuracy: 0.334000\n",
      "lr 5.000000e-07 reg 2.500000e+04 train accuracy: 0.344061 val accuracy: 0.363000\n",
      "lr 5.000000e-07 reg 3.125000e+04 train accuracy: 0.344367 val accuracy: 0.346000\n",
      "lr 5.000000e-07 reg 3.750000e+04 train accuracy: 0.341918 val accuracy: 0.355000\n",
      "lr 5.000000e-07 reg 4.375000e+04 train accuracy: 0.331347 val accuracy: 0.343000\n",
      "lr 5.000000e-07 reg 5.000000e+04 train accuracy: 0.324061 val accuracy: 0.339000\n",
      "best validation accuracy achieved during cross-validation: 0.369000\n"
     ]
    }
   ],
   "source": [
    "# Use the validation set to tune hyperparameters (regularization strength and\n",
    "# learning rate). You should experiment with different ranges for the learning\n",
    "# rates and regularization strengths; if you are careful you should be able to\n",
    "# get a classification accuracy of over 0.35 on the validation set.\n",
    "from cs231n.classifiers import Softmax\n",
    "results = {}\n",
    "best_val = -1\n",
    "best_softmax = None\n",
    "learning_rates = [1e-7, 5e-7]\n",
    "regularization_strengths = [2.5e4, 5e4]\n",
    "\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Use the validation set to set the learning rate and regularization strength. #\n",
    "# This should be identical to the validation that you did for the SVM; save    #\n",
    "# the best trained softmax classifer in best_softmax.                          #\n",
    "################################################################################\n",
    "\n",
    "# additional variables \n",
    "best_lr = None\n",
    "best_reg = None\n",
    "\n",
    "range_lr = np.linspace(learning_rates[0],learning_rates[1],5)\n",
    "range_reg = np.linspace(regularization_strengths[0],regularization_strengths[1],5)\n",
    "\n",
    "print (\"strating loop ! This may take a while\\n\\n\")\n",
    "# loop through all the combinations\n",
    "for cur_lr in range_lr: #go over the learning rates\n",
    "    for cur_reg in range_reg:#go over the regularization strength\n",
    "        # initiate linear classifier with hyperparameters\n",
    "        smx = Softmax()\n",
    "        smx.train(X_train, y_train, learning_rate=cur_lr, reg=cur_reg,num_iters=1600, verbose=True)\n",
    "        \n",
    "        # Training\n",
    "        y_pred = smx.predict(X_train)\n",
    "        train_accuracy = np.mean(np.equal(y_train, y_pred, dtype=float))\n",
    "\n",
    "        # Validation\n",
    "        y_pred = smx.predict(X_val)  \n",
    "        val_accuracy = np.mean(np.equal(y_val, y_pred, dtype=float))\n",
    "  \n",
    "        results[(cur_lr, cur_reg)] = (train_accuracy, val_accuracy)\n",
    "  \n",
    "        if val_accuracy > best_val:\n",
    "            best_val = val_accuracy\n",
    "            best_softmax = smx\n",
    "            best_lr = cur_lr\n",
    "            best_reg = cur_reg\n",
    "\n",
    "# best results printed (from my run I got these values, also shown below)\n",
    "# best_val     0.369\n",
    "# best_lr      2e-07\n",
    "# best_reg     37500.0\n",
    "# best validation during cross-validation: 0.369000\n",
    "\n",
    "print (\"\\n****\\ndone comparing\\n****\")\n",
    "print (\"\\nbest_val    \",best_val)\n",
    "print (\"\\nbest_lr     \",best_lr)\n",
    "print (\"\\nbest_reg    \",best_reg)\n",
    "print (\"\\nbest Softmax model saved :)\\n\")\n",
    "\n",
    "# Print out results.\n",
    "for lr, reg in sorted(results):\n",
    "    train_accuracy, val_accuracy = results[(lr, reg)]\n",
    "    print('lr %e reg %e train accuracy: %f val accuracy: %f' % (\n",
    "                lr, reg, train_accuracy, val_accuracy))\n",
    "    \n",
    "print('best validation accuracy achieved during cross-validation: %f' % best_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax on raw pixels final test set accuracy: 0.360000\n"
     ]
    }
   ],
   "source": [
    "# evaluate on test set\n",
    "# Evaluate the best softmax on test set\n",
    "y_test_pred = best_softmax.predict(X_test)\n",
    "test_accuracy = np.mean(y_test == y_test_pred)\n",
    "print('softmax on raw pixels final test set accuracy: %f' % (test_accuracy, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inline Question** - *True or False*\n",
    "\n",
    "It's possible to add a new datapoint to a training set that would leave the SVM loss unchanged, but this is not the case with the Softmax classifier loss.\n",
    "\n",
    "*Your answer*: True\n",
    "\n",
    "*Your explanation*: The SVM does not care much about the margin differences, whilst for the Softmax classifier, this improves the probability, as these are based on the magnitudes of the scores. From notes, compared to the Softmax classifier, the SVM is a more local objective, which could be thought of either as a bug or a feature. The Softmax classifier is never fully happy with the scores it produces: the correct class could always have a higher probability and the incorrect classes always a lower probability and the loss would always get better. An additional data point could thus impact the loss significantly or insignificantly depending on the sample size. \n",
    "\n",
    "** These weights(class templates) below are similar to the weights I got from the linear_SVM, which is of no suprise, as the same dataset was used for training. They look much better and more refined than the SVM, from a human eye perspective **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the learned weights for each class\n",
    "w = best_softmax.W[:-1,:] # strip out the bias\n",
    "w = w.reshape(32, 32, 3, 10)\n",
    "\n",
    "w_min, w_max = np.min(w), np.max(w)\n",
    "\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    \n",
    "    # Rescale the weights to be between 0 and 255\n",
    "    wimg = 255.0 * (w[:, :, :, i].squeeze() - w_min) / (w_max - w_min)\n",
    "    plt.imshow(wimg.astype('uint8'))\n",
    "    plt.axis('off')\n",
    "    plt.title(classes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
